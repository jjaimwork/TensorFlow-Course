{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Regression with Neural Networks in Tensorflow\n",
    "\n",
    "There are many definitions fora  regression problem but inm our case, we're going to simplify it: predicting a numerical variable based on some other combinations of variables, even shorter... predicting a number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "# import tensorflow\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating data to view and fit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# create features\n",
    "X = np.array([-7.0, -4.0, -1.0, 2.0, 5.0, 8.0, 11.0, 14.0])\n",
    "\n",
    "# create labels\n",
    "y = np.array([3.0, 6.0, 9.0, 12.0, 15.0, 18.0, 21.0, 24.0])\n",
    "\n",
    "plt.scatter(X, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'bedroom', b'bathroom', b'garage'], dtype=object)>,\n",
       " <tf.Tensor: shape=(1,), dtype=int32, numpy=array([939700])>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a demo tensor for our housing price prediction problem\n",
    "house_info = tf.constant(['bedroom', 'bathroom', 'garage'])\n",
    "house_price = tf.constant([939700])\n",
    "house_info, house_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert x and y into tensors\n",
    "X = tf.constant(X)\n",
    "y = tf.constant(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps in modelling with TensorFlow\n",
    "\n",
    "1. **Creating a model** - define the input and outpul layers, as well as the hidden layers ofa deep learning model.\n",
    "2. **Compiling a model** - define the loss function (in other words, the function which tells our model how wrong it is) and the optimizer (tells our model how to improve the patterns it's learning) and the evaluation metrics (what we can use to interpret the performance of our model).\n",
    " * Loss - How wrong your model's predictions are compared to the truth labels.\n",
    " * Optimizer - How your model should update its internal patterns to better its predictions.\n",
    " * Metrics - Human interpretable values for how well your model is doing.\n",
    "3. **Fitting a model** - letting the model try to find patterns between X & y (feature and labels).\n",
    " * Epochs - how many times the model will go through all of the training examples.\n",
    "4. Evaluate the model on the test data (how reliable are our model's predictions?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1/1 [==============================] - 1s 1s/step - loss: 11.5048 - mae: 11.5048\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 11.3723 - mae: 11.3723\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 11.2398 - mae: 11.2398\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 11.1073 - mae: 11.1073\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.9748 - mae: 10.9748\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x28ed48f9d90>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. create a model using the sequential API\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. compile the model\n",
    "model.compile(loss=tf.keras.losses.mae, \n",
    "             optimizer=tf.keras.optimizers.SGD(),\n",
    "             metrics=['mae'])\n",
    "\n",
    "# 3. fit the model\n",
    "model.fit(X, y, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12.716021]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict using our model\n",
    "model.predict([17.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving our model\n",
    "\n",
    "We can improve our model, by altering the steps we took to create a model.\n",
    "\n",
    "1. **Creating a model** - here we might add more layers, increase the number of hidden units(all called neurons) within each of the hidden layers, change the activation functions of each layer.\n",
    "2. **Compiling a model** - here we might change the optimization function or perhaps the **learning rate** of the optimization function\n",
    "3. **Fitting a model** - here we might fit a model for more **epochs** ( leave it training for longer or more data(give the model more examples to learn from).\n",
    "\n",
    "### Common ways to improve a deep learning model:\n",
    "1. Adding layers\n",
    "2. Increase the number of hidden units\n",
    "3. Change the activation function\n",
    "4. Change the optimization function\n",
    "5. Change the learning rate\n",
    "\n",
    "### Evaluating a model\n",
    "\n",
    "In practice, a typical workflow you'll go through when building neural networks is: \n",
    "```\n",
    "Build a model -> Fit it -> Evaluate it -> Tweak a model -> Fit it -> Evaluate it -> Tweak a model -> Fit it -> Evaluate it ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 11.2219 - mae: 11.2219\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 11.0894 - mae: 11.0894\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.9569 - mae: 10.9569\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.8244 - mae: 10.8244\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.6919 - mae: 10.6919\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5594 - mae: 10.5594\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.4269 - mae: 10.4269\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.2944 - mae: 10.2944\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.1619 - mae: 10.1619\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.0294 - mae: 10.0294\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.8969 - mae: 9.8969\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.7644 - mae: 9.7644\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.6319 - mae: 9.6319\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.4994 - mae: 9.4994\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.3669 - mae: 9.3669\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.2344 - mae: 9.2344\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.1019 - mae: 9.1019\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.9694 - mae: 8.9694\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 8.8369 - mae: 8.8369\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 8.7044 - mae: 8.7044\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.5719 - mae: 8.5719\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.4394 - mae: 8.4394\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.3069 - mae: 8.3069\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.1744 - mae: 8.1744\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 8.0419 - mae: 8.0419\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 7.9094 - mae: 7.9094\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.7769 - mae: 7.7769\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.6444 - mae: 7.6444\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.5119 - mae: 7.5119\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.3794 - mae: 7.3794\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.2750 - mae: 7.2750\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.2694 - mae: 7.2694\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.2638 - mae: 7.2638\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.2581 - mae: 7.2581\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.2525 - mae: 7.2525\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.2469 - mae: 7.2469\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.2413 - mae: 7.2413\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.2356 - mae: 7.2356\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.2300 - mae: 7.2300\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.2244 - mae: 7.2244\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.2188 - mae: 7.2188\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.2131 - mae: 7.2131\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 7.2075 - mae: 7.2075\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.2019 - mae: 7.2019\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.1962 - mae: 7.1962\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.1906 - mae: 7.1906\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.1850 - mae: 7.1850\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.1794 - mae: 7.1794\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.1737 - mae: 7.1737\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.1681 - mae: 7.1681\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.1625 - mae: 7.1625\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.1569 - mae: 7.1569\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.1512 - mae: 7.1512\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.1456 - mae: 7.1456\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.1400 - mae: 7.1400\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.1344 - mae: 7.1344\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.1287 - mae: 7.1287\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.1231 - mae: 7.1231\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 7.1175 - mae: 7.1175\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.1119 - mae: 7.1119\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.1062 - mae: 7.1062\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 7.1006 - mae: 7.1006\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 7.0950 - mae: 7.0950\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.0894 - mae: 7.0894\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.0838 - mae: 7.0838\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.0781 - mae: 7.0781\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.0725 - mae: 7.0725\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.0669 - mae: 7.0669\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.0613 - mae: 7.0613\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.0556 - mae: 7.0556\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 7.0500 - mae: 7.0500\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.0444 - mae: 7.0444\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.0388 - mae: 7.0388\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.0331 - mae: 7.0331\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.0275 - mae: 7.0275\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.0219 - mae: 7.0219\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.0163 - mae: 7.0163\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.0106 - mae: 7.0106\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.0050 - mae: 7.0050\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.9994 - mae: 6.9994\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.9938 - mae: 6.9938\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.9881 - mae: 6.9881\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.9825 - mae: 6.9825\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.9769 - mae: 6.9769\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.9713 - mae: 6.9713\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.9656 - mae: 6.9656\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.9600 - mae: 6.9600\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 6.9544 - mae: 6.9544\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.9488 - mae: 6.9488\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.9431 - mae: 6.9431\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.9375 - mae: 6.9375\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 6.9319 - mae: 6.9319\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.9262 - mae: 6.9262\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.9206 - mae: 6.9206\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.9150 - mae: 6.9150\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.9094 - mae: 6.9094\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.9038 - mae: 6.9038\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.8981 - mae: 6.8981\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 6.8925 - mae: 6.8925\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.8869 - mae: 6.8869\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x28ef0286940>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rebuilding our model\n",
    "\n",
    "# 1. Create the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "             optimizer=tf.keras.optimizers.SGD(),\n",
    "             metrics=['mae'])\n",
    "\n",
    "# 3. Fit the model(this time train for longer)\n",
    "model.fit(X,y, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[29.739855]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicting the model\n",
    "model.predict([17.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 10.5736 - mae: 10.5736\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5731 - mae: 10.5731\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.5727 - mae: 10.5727\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5722 - mae: 10.5722\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5718 - mae: 10.5718\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5713 - mae: 10.5713\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5709 - mae: 10.5709\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5704 - mae: 10.5704\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5700 - mae: 10.5700\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5695 - mae: 10.5695\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5691 - mae: 10.5691\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5686 - mae: 10.5686\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5682 - mae: 10.5682\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5677 - mae: 10.5677\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5673 - mae: 10.5673\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 10.5668 - mae: 10.5668\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5664 - mae: 10.5664\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5659 - mae: 10.5659\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5655 - mae: 10.5655\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.5650 - mae: 10.5650\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5646 - mae: 10.5646\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5641 - mae: 10.5641\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5637 - mae: 10.5637\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5632 - mae: 10.5632\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5628 - mae: 10.5628\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5623 - mae: 10.5623\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5619 - mae: 10.5619\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5614 - mae: 10.5614\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5610 - mae: 10.5610\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.5605 - mae: 10.5605\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5601 - mae: 10.5601\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5596 - mae: 10.5596\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.5592 - mae: 10.5592\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.5587 - mae: 10.5587\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5583 - mae: 10.5583\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5578 - mae: 10.5578\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5574 - mae: 10.5574\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5569 - mae: 10.5569\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5565 - mae: 10.5565\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5560 - mae: 10.5560\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5556 - mae: 10.5556\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5551 - mae: 10.5551\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5547 - mae: 10.5547\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5542 - mae: 10.5542\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5538 - mae: 10.5538\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5533 - mae: 10.5533\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.5529 - mae: 10.5529\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5524 - mae: 10.5524\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.5520 - mae: 10.5520\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.5515 - mae: 10.5515\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5511 - mae: 10.5511\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.5506 - mae: 10.5506\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5502 - mae: 10.5502\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5497 - mae: 10.5497\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5493 - mae: 10.5493\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5488 - mae: 10.5488\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5484 - mae: 10.5484\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5479 - mae: 10.5479\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5475 - mae: 10.5475\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.5470 - mae: 10.5470\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.5466 - mae: 10.5466\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5461 - mae: 10.5461\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.5457 - mae: 10.5457\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5452 - mae: 10.5452\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.5448 - mae: 10.5448\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5443 - mae: 10.5443\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5439 - mae: 10.5439\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5434 - mae: 10.5434\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5430 - mae: 10.5430\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5425 - mae: 10.5425\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5421 - mae: 10.5421\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5416 - mae: 10.5416\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5412 - mae: 10.5412\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5407 - mae: 10.5407\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5403 - mae: 10.5403\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5398 - mae: 10.5398\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5394 - mae: 10.5394\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5389 - mae: 10.5389\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5385 - mae: 10.5385\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.5380 - mae: 10.5380\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5376 - mae: 10.5376\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5371 - mae: 10.5371\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 10.5367 - mae: 10.5367\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5362 - mae: 10.5362\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.5358 - mae: 10.5358\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 10.5353 - mae: 10.5353\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5349 - mae: 10.5349\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5344 - mae: 10.5344\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5340 - mae: 10.5340\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 10.5335 - mae: 10.5335\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5331 - mae: 10.5331\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5326 - mae: 10.5326\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5322 - mae: 10.5322\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5317 - mae: 10.5317\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5313 - mae: 10.5313\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5308 - mae: 10.5308\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5304 - mae: 10.5304\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.5299 - mae: 10.5299\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.5295 - mae: 10.5295\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.5290 - mae: 10.5290\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x28ff7ad4670>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rebuilding our model using adam\n",
    "\n",
    "# 1. Create the model\n",
    "model_adam = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model_adam.compile(loss=tf.keras.losses.mae,\n",
    "             optimizer=tf.keras.optimizers.Adam(lr=0.0001),\n",
    "             metrics=['mae'])\n",
    "\n",
    "# 3. Fit the model(this time train for longer)\n",
    "model_adam.fit(X,y, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14.394114]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicting the model\n",
    "model_adam.predict([17.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 14.2261 - mae: 14.2261\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 13.7228 - mae: 13.7228\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 13.2221 - mae: 13.2221\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.7213 - mae: 12.7213\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 12.2178 - mae: 12.2178\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.7090 - mae: 11.7090\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.1924 - mae: 11.1924\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.6652 - mae: 10.6652\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.1247 - mae: 10.1247\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.5681 - mae: 9.5681\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.9927 - mae: 8.9927\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.3954 - mae: 8.3954\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.7732 - mae: 7.7732\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.1712 - mae: 7.1712\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.1502 - mae: 7.1502\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.1291 - mae: 7.1291\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.1080 - mae: 7.1080\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.0868 - mae: 7.0868\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.0656 - mae: 7.0656\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.0443 - mae: 7.0443\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.0229 - mae: 7.0229\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 7.0014 - mae: 7.0014\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.9799 - mae: 6.9799\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.9583 - mae: 6.9583\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.9366 - mae: 6.9366\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.9148 - mae: 6.9148\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.8929 - mae: 6.8929\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.8710 - mae: 6.8710\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.8489 - mae: 6.8489\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.8267 - mae: 6.8267\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.8044 - mae: 6.8044\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.7820 - mae: 6.7820\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.7595 - mae: 6.7595\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.7369 - mae: 6.7369\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.7141 - mae: 6.7141\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.6912 - mae: 6.6912\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.6682 - mae: 6.6682\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.6451 - mae: 6.6451\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.6218 - mae: 6.6218\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.5984 - mae: 6.5984\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.5748 - mae: 6.5748\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.5511 - mae: 6.5511\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.5272 - mae: 6.5272\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.5032 - mae: 6.5032\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.4790 - mae: 6.4790\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.4546 - mae: 6.4546\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.4455 - mae: 6.4455\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.4258 - mae: 6.4258\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.4015 - mae: 6.4015\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3770 - mae: 6.3770\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3524 - mae: 6.3524\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3275 - mae: 6.3275\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3025 - mae: 6.3025\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.2773 - mae: 6.2773\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.2519 - mae: 6.2519\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.2262 - mae: 6.2262\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.2004 - mae: 6.2004\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.1743 - mae: 6.1743\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.1481 - mae: 6.1481\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.1216 - mae: 6.1216\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.0949 - mae: 6.0949\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.0679 - mae: 6.0679\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.0407 - mae: 6.0407\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.0133 - mae: 6.0133\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.9856 - mae: 5.9856\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.9780 - mae: 5.9780\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.9553 - mae: 5.9553\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.9274 - mae: 5.9274\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.8993 - mae: 5.8993\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.8710 - mae: 5.8710\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.8423 - mae: 5.8423\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.8134 - mae: 5.8134\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.7842 - mae: 5.7842\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.7547 - mae: 5.7547\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.7249 - mae: 5.7249\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 999us/step - loss: 5.6949 - mae: 5.6949\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.6645 - mae: 5.6645\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.6338 - mae: 5.6338\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.6028 - mae: 5.6028\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.5715 - mae: 5.5715\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.5398 - mae: 5.5398\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.5274 - mae: 5.5274\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.5195 - mae: 5.5195\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.6334 - mae: 5.6334\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.4375 - mae: 5.4375\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.4047 - mae: 5.4047\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.3715 - mae: 5.3715\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.3379 - mae: 5.3379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.3040 - mae: 5.3040\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.2697 - mae: 5.2697\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.2351 - mae: 5.2351\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.2000 - mae: 5.2000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.1780 - mae: 5.1780\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.2329 - mae: 5.2329\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.2873 - mae: 5.2873\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.0863 - mae: 5.0863\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.0497 - mae: 5.0497\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.0127 - mae: 5.0127\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.9754 - mae: 4.9754\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.9375 - mae: 4.9375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x290052d1b80>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rebuilding our model adding hidden layer\n",
    "\n",
    "# 1. Create the model\n",
    "model_layer = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(50, activation=None),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model_layer.compile(loss=tf.keras.losses.mae,\n",
    "             optimizer=tf.keras.optimizers.SGD(),\n",
    "             metrics=['mae'])\n",
    "\n",
    "# 3. Fit the model(this time train for longer)\n",
    "model_layer.fit(X,y, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[30.073227]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicting the model\n",
    "model_layer.predict([17.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 13.0174 - mae: 13.0174\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 12.9723 - mae: 12.9723\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 12.9271 - mae: 12.9271\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.8814 - mae: 12.8814\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 12.8340 - mae: 12.8340\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 12.7858 - mae: 12.7858\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.7374 - mae: 12.7374\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.6890 - mae: 12.6890\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 12.6405 - mae: 12.6405\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 12.5920 - mae: 12.5920\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 12.5434 - mae: 12.5434\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.4948 - mae: 12.4948\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 12.4466 - mae: 12.4466\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.3990 - mae: 12.3990\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 12.3510 - mae: 12.3510\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 12.3027 - mae: 12.3027\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 12.2543 - mae: 12.2543\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.2056 - mae: 12.2056\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.1569 - mae: 12.1569\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.1083 - mae: 12.1083\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.0597 - mae: 12.0597\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.0110 - mae: 12.0110\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.9621 - mae: 11.9621\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.9131 - mae: 11.9131\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 11.8639 - mae: 11.8639\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.8152 - mae: 11.8152\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.7671 - mae: 11.7671\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.7188 - mae: 11.7188\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.6700 - mae: 11.6700\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.6209 - mae: 11.6209\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.5714 - mae: 11.5714\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.5217 - mae: 11.5217\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.4720 - mae: 11.4720\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 11.4221 - mae: 11.4221\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.3719 - mae: 11.3719\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.3215 - mae: 11.3215\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.2707 - mae: 11.2707\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.2191 - mae: 11.2191\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.1672 - mae: 11.1672\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.1150 - mae: 11.1150\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.0626 - mae: 11.0626\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 11.0091 - mae: 11.0091\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.9551 - mae: 10.9551\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.9004 - mae: 10.9004\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.8452 - mae: 10.8452\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.7889 - mae: 10.7889\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.7322 - mae: 10.7322\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.6750 - mae: 10.6750\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.6172 - mae: 10.6172\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.5592 - mae: 10.5592\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.5016 - mae: 10.5016\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.4443 - mae: 10.4443\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.3868 - mae: 10.3868\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.3288 - mae: 10.3288\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.2704 - mae: 10.2704\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.2115 - mae: 10.2115\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.1550 - mae: 10.1550\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.1091 - mae: 10.1091\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.0629 - mae: 10.0629\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.0165 - mae: 10.0165\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.9701 - mae: 9.9701\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.9232 - mae: 9.9232\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.8760 - mae: 9.8760\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.8283 - mae: 9.8283\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.7802 - mae: 9.7802\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.7316 - mae: 9.7316\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.6827 - mae: 9.6827\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.6335 - mae: 9.6335\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.5842 - mae: 9.5842\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.5347 - mae: 9.5347\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.4851 - mae: 9.4851\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.4367 - mae: 9.4367\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.3880 - mae: 9.3880\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.3389 - mae: 9.3389\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.2892 - mae: 9.2892\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 9.2388 - mae: 9.2388\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.1879 - mae: 9.1879\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.1365 - mae: 9.1365\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.0846 - mae: 9.0846\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.0322 - mae: 9.0322\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.9794 - mae: 8.9794\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.9261 - mae: 8.9261\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.8721 - mae: 8.8721\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.8176 - mae: 8.8176\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.7626 - mae: 8.7626\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.7072 - mae: 8.7072\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 4ms/step - loss: 8.6513 - mae: 8.6513\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.5951 - mae: 8.5951\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.5385 - mae: 8.5385\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.4813 - mae: 8.4813\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.4235 - mae: 8.4235\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.3653 - mae: 8.3653\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.3066 - mae: 8.3066\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.2473 - mae: 8.2473\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.1875 - mae: 8.1875\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.1270 - mae: 8.1270\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.0658 - mae: 8.0658\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.0042 - mae: 8.0042\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.9419 - mae: 7.9419\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.8790 - mae: 7.8790\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2900b2ceb80>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rebuilding our model using both\n",
    "\n",
    "# 1. Create the model\n",
    "model_last = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model_last.compile(loss=tf.keras.losses.mae,\n",
    "             optimizer=tf.keras.optimizers.Adam(lr=0.0001),\n",
    "             metrics=['mae'])\n",
    "\n",
    "# 3. Fit the model(this time train for longer)\n",
    "model_last.fit(X,y, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\User\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:805 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\User\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\User\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\User\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\User\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\User\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:788 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\User\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:757 train_step\n        self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    C:\\Users\\User\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:498 minimize\n        return self.apply_gradients(grads_and_vars, name=name)\n    C:\\Users\\User\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:598 apply_gradients\n        grads_and_vars = optimizer_utils.filter_empty_gradients(grads_and_vars)\n    C:\\Users\\User\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\utils.py:78 filter_empty_gradients\n        raise ValueError(\"No gradients provided for any variable: %s.\" %\n\n    ValueError: No gradients provided for any variable: ['dense_5/kernel:0', 'dense_5/bias:0', 'dense_6/kernel:0', 'dense_6/bias:0', 'dense_7/kernel:0', 'dense_7/bias:0', 'dense_8/kernel:0', 'dense_8/bias:0'].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-e89dcc38b4b5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel_last\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m17.0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2939\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m-> 2941\u001b[1;33m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[0;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3355\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_signature\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3356\u001b[0m               call_context_key in self._function_cache.missed):\n\u001b[1;32m-> 3357\u001b[1;33m             return self._define_function_with_shape_relaxation(\n\u001b[0m\u001b[0;32m   3358\u001b[0m                 args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[0;32m   3359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[1;34m(self, args, kwargs, flat_args, filtered_flat_args, cache_key_context)\u001b[0m\n\u001b[0;32m   3277\u001b[0m           expand_composites=True)\n\u001b[0;32m   3278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3279\u001b[1;33m     graph_function = self._create_graph_function(\n\u001b[0m\u001b[0;32m   3280\u001b[0m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0;32m   3281\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3194\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3195\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3196\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3197\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3198\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    989\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 990\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    991\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    992\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 634\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    635\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    975\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    976\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 977\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    978\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    979\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\User\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:805 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\User\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\User\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\User\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\User\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\User\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:788 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\User\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:757 train_step\n        self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    C:\\Users\\User\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:498 minimize\n        return self.apply_gradients(grads_and_vars, name=name)\n    C:\\Users\\User\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:598 apply_gradients\n        grads_and_vars = optimizer_utils.filter_empty_gradients(grads_and_vars)\n    C:\\Users\\User\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\utils.py:78 filter_empty_gradients\n        raise ValueError(\"No gradients provided for any variable: %s.\" %\n\n    ValueError: No gradients provided for any variable: ['dense_5/kernel:0', 'dense_5/bias:0', 'dense_6/kernel:0', 'dense_6/bias:0', 'dense_7/kernel:0', 'dense_7/bias:0', 'dense_8/kernel:0', 'dense_8/bias:0'].\n"
     ]
    }
   ],
   "source": [
    "model_last.fit([17.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
